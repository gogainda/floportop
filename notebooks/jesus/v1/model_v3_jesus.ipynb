{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb40602",
   "metadata": {},
   "source": "# Model Training v3 (Combined Datasets)\n\n**Goal:** Train and compare models using features from both IMDb and TMDb.\n\n**Inputs:**\n- `data/movies_wide.csv` (IMDb features, ~298k movies)\n- `data/tmdb_wide.csv` (TMDb features + Plot PCA, ~44k movies)\n\n**Strategy:**\n1. Merge datasets (Left Join on IMDb ID).\n2. **Full Dataset Experiments** (298k movies, 85% without TMDb data):\n   - Experiment 1: Baseline (IMDb features only)\n   - Experiment 2: Add Plot PCA features (fill missing with 0)\n3. **Subset Experiments** (44k movies WITH TMDb data):\n   - Experiment 3: Baseline on subset\n   - Experiment 4: Baseline + PCA on subset ‚Üí **True plot impact**\n\n**Why subset experiments matter:**\nTesting on all 298k movies dilutes the plot signal because 85% have no plot data (filled with 0s).\nThe subset experiments show the real R¬≤ improvement when a user actually provides a plot."
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e856b3b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T14:54:05.938308Z",
     "iopub.status.busy": "2026-01-28T14:54:05.937924Z",
     "iopub.status.idle": "2026-01-28T14:54:07.845929Z",
     "shell.execute_reply": "2026-01-28T14:54:07.845658Z",
     "shell.execute_reply.started": "2026-01-28T14:54:05.938277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path('../data')\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f35b39f",
   "metadata": {},
   "source": [
    "## 1. Load and Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b691e46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T14:54:08.684019Z",
     "iopub.status.busy": "2026-01-28T14:54:08.683734Z",
     "iopub.status.idle": "2026-01-28T14:54:09.551123Z",
     "shell.execute_reply": "2026-01-28T14:54:09.550870Z",
     "shell.execute_reply.started": "2026-01-28T14:54:08.684005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDb wide shape: (298616, 32)\n",
      "TMDb wide shape: (43995, 26)\n",
      "Lengths match. Attaching tconst to imdb_wide...\n",
      "Movies with TMDb data: 37,905 (12.7%)\n",
      "Merged dataset shape: (298616, 60)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>averageRating</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>genre_count</th>\n",
       "      <th>decade</th>\n",
       "      <th>movie_age</th>\n",
       "      <th>runtimeMinutes_capped</th>\n",
       "      <th>log_numVotes</th>\n",
       "      <th>hit</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_11</th>\n",
       "      <th>pca_12</th>\n",
       "      <th>pca_13</th>\n",
       "      <th>pca_14</th>\n",
       "      <th>pca_15</th>\n",
       "      <th>pca_16</th>\n",
       "      <th>pca_17</th>\n",
       "      <th>pca_18</th>\n",
       "      <th>pca_19</th>\n",
       "      <th>has_tmdb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1894.0</td>\n",
       "      <td>232</td>\n",
       "      <td>1</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>45</td>\n",
       "      <td>5.451038</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>584</td>\n",
       "      <td>3</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>100</td>\n",
       "      <td>6.371612</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>40</td>\n",
       "      <td>4.219508</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>1046</td>\n",
       "      <td>3</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>70</td>\n",
       "      <td>6.953684</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013349</td>\n",
       "      <td>-0.123792</td>\n",
       "      <td>-0.023552</td>\n",
       "      <td>0.113217</td>\n",
       "      <td>-0.136703</td>\n",
       "      <td>0.022376</td>\n",
       "      <td>-0.090953</td>\n",
       "      <td>0.011291</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>90</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   averageRating  isAdult  startYear  numVotes  genre_count  decade  \\\n",
       "0            5.2        0     1894.0       232            1  1890.0   \n",
       "1            5.3        0     1897.0       584            3  1890.0   \n",
       "2            5.4        0     1900.0        67            2  1900.0   \n",
       "3            6.0        0     1906.0      1046            3  1900.0   \n",
       "4            4.8        0     1907.0        37            1  1900.0   \n",
       "\n",
       "   movie_age  runtimeMinutes_capped  log_numVotes  hit  ...    pca_11  \\\n",
       "0      132.0                     45      5.451038    0  ...  0.000000   \n",
       "1      129.0                    100      6.371612    0  ...  0.000000   \n",
       "2      126.0                     40      4.219508    0  ...  0.000000   \n",
       "3      120.0                     70      6.953684    1  ...  0.013349   \n",
       "4      119.0                     90      3.637586    0  ...  0.000000   \n",
       "\n",
       "     pca_12    pca_13    pca_14    pca_15    pca_16    pca_17    pca_18  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3 -0.123792 -0.023552  0.113217 -0.136703  0.022376 -0.090953  0.011291   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "     pca_19  has_tmdb  \n",
       "0  0.000000         0  \n",
       "1  0.000000         0  \n",
       "2  0.000000         0  \n",
       "3  0.062831         1  \n",
       "4  0.000000         0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load datasets\n",
    "imdb = pd.read_csv(DATA_DIR / 'movies_clean.csv') # Need tconst for merging\n",
    "imdb_wide = pd.read_csv(DATA_DIR / 'movies_wide.csv')\n",
    "tmdb_wide = pd.read_csv(DATA_DIR / 'tmdb_wide.csv')\n",
    "\n",
    "print(f\"IMDb wide shape: {imdb_wide.shape}\")\n",
    "print(f\"TMDb wide shape: {tmdb_wide.shape}\")\n",
    "\n",
    "# Note: movies_wide.csv lost tconst, so we need to be careful.\n",
    "# Assuming row alignment is preserved from movies_clean.csv is risky.\n",
    "# Better approach: We'll reconstruct the full dataset using movies_clean as the anchor.\n",
    "\n",
    "# Let's check if movies_wide has the same length as movies_clean\n",
    "if len(imdb) != len(imdb_wide):\n",
    "    print(\"Warning: Length mismatch!\")\n",
    "else:\n",
    "    print(\"Lengths match. Attaching tconst to imdb_wide...\")\n",
    "    imdb_wide['tconst'] = imdb['tconst']\n",
    "\n",
    "# Merge TMDb features\n",
    "# Left join: Keep all IMDb movies, add TMDb info where available\n",
    "merged = imdb_wide.merge(tmdb_wide, left_on='tconst', right_on='imdbId', how='left')\n",
    "\n",
    "# Create has_tmdb flag BEFORE filling with 0s\n",
    "# A movie has TMDb data if imdbId is not null after the merge\n",
    "merged['has_tmdb'] = merged['imdbId'].notna().astype(int)\n",
    "\n",
    "print(f\"Movies with TMDb data: {merged['has_tmdb'].sum():,} ({merged['has_tmdb'].mean()*100:.1f}%)\")\n",
    "\n",
    "# Fill missing TMDb features with 0\n",
    "# Identify new columns (those from tmdb_wide)\n",
    "tmdb_cols = [c for c in tmdb_wide.columns if c != 'imdbId']\n",
    "merged[tmdb_cols] = merged[tmdb_cols].fillna(0)\n",
    "\n",
    "print(f\"Merged dataset shape: {merged.shape}\")\n",
    "display(merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe93adb8",
   "metadata": {},
   "source": [
    "## 2. Define Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c14ba17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T14:54:19.571583Z",
     "iopub.status.busy": "2026-01-28T14:54:19.571032Z",
     "iopub.status.idle": "2026-01-28T14:54:19.578067Z",
     "shell.execute_reply": "2026-01-28T14:54:19.577192Z",
     "shell.execute_reply.started": "2026-01-28T14:54:19.571556Z"
    }
   },
   "outputs": [],
   "source": "# Identify feature groups\ntarget = 'averageRating'\nignore_cols = ['tconst', 'imdbId', 'director_names', target] # director_names needs processing if we want to use it\n\n# 1. Base Features (from IMDb)\nbase_features = [c for c in imdb_wide.columns if c not in ignore_cols and c != 'tconst']\n\n# 2. PCA Features\npca_features = [c for c in merged.columns if c.startswith('pca_')]\n\n# 3. Budget/Revenue\nmoney_features = ['log_budget', 'log_revenue']\n\n# Print feature sets clearly\nprint(\"=\" * 60)\nprint(\"FEATURE SETS\")\nprint(\"=\" * 60)\n\nprint(f\"\\nüìä BASE FEATURES ({len(base_features)} columns):\")\nprint(\"-\" * 40)\nfor i, f in enumerate(base_features):\n    print(f\"  {i+1:2}. {f}\")\n\nprint(f\"\\nüé¨ PCA FEATURES ({len(pca_features)} columns):\")\nprint(\"-\" * 40)\nprint(f\"  pca_0 to pca_{len(pca_features)-1} (from plot embeddings)\")\n\nprint(f\"\\nüí∞ MONEY FEATURES ({len(money_features)} columns):\")\nprint(\"-\" * 40)\nfor f in money_features:\n    print(f\"  - {f}\")\n\nprint(\"\\n\" + \"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "id": "3f1b600a",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00b4449d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T14:54:21.580781Z",
     "iopub.status.busy": "2026-01-28T14:54:21.580394Z",
     "iopub.status.idle": "2026-01-28T14:54:21.803442Z",
     "shell.execute_reply": "2026-01-28T14:54:21.803142Z",
     "shell.execute_reply.started": "2026-01-28T14:54:21.580753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 209,015\n",
      "Test size: 89,579\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaN in target or base features (should be none for base)\n",
    "df_model = merged.dropna(subset=[target] + base_features)\n",
    "\n",
    "X = df_model.drop(columns=[target, 'tconst', 'imdbId', 'director_names'])\n",
    "y = df_model[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Train size: {len(X_train):,}\")\n",
    "print(f\"Test size: {len(X_test):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c027733",
   "metadata": {},
   "source": [
    "## 4. Experiment 1: Baseline on Full Dataset (IMDb Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ded7792e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T14:54:27.600502Z",
     "iopub.status.busy": "2026-01-28T14:54:27.600102Z",
     "iopub.status.idle": "2026-01-28T14:54:32.550028Z",
     "shell.execute_reply": "2026-01-28T14:54:32.549546Z",
     "shell.execute_reply.started": "2026-01-28T14:54:27.600474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Baseline Model...\n",
      "Baseline R¬≤: 0.3117\n",
      "Baseline MAE: 0.8535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline R¬≤: 0.3117\n",
      "Baseline MAE: 0.8535\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Baseline Model...\")\n",
    "rf_base = RandomForestRegressor(n_estimators=50, max_depth=10, n_jobs=-1, random_state=42)\n",
    "rf_base.fit(X_train[base_features], y_train)\n",
    "\n",
    "y_pred_base = rf_base.predict(X_test[base_features])\n",
    "r2_base = r2_score(y_test, y_pred_base)\n",
    "mae_base = mean_absolute_error(y_test, y_pred_base)\n",
    "\n",
    "print(f\"Baseline R¬≤: {r2_base:.4f}\")\n",
    "print(f\"Baseline MAE: {mae_base:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c0b9d7",
   "metadata": {},
   "source": [
    "## 5. Experiment 2: Baseline + Plot PCA on Full Dataset (0-filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47e59b3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T14:55:14.970547Z",
     "iopub.status.busy": "2026-01-28T14:55:14.967960Z",
     "iopub.status.idle": "2026-01-28T14:55:25.171913Z",
     "shell.execute_reply": "2026-01-28T14:55:25.171637Z",
     "shell.execute_reply.started": "2026-01-28T14:55:14.970473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model with Plots (51 features)...\n",
      "PCA Model R¬≤: 0.3119\n",
      "PCA Model MAE: 0.8535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Model R¬≤: 0.3119\n",
      "PCA Model MAE: 0.8535\n"
     ]
    }
   ],
   "source": [
    "features_v2 = base_features + pca_features\n",
    "print(f\"Training Model with Plots ({len(features_v2)} features)...\")\n",
    "\n",
    "rf_pca = RandomForestRegressor(n_estimators=50, max_depth=10, n_jobs=-1, random_state=42)\n",
    "rf_pca.fit(X_train[features_v2], y_train)\n",
    "\n",
    "y_pred_pca = rf_pca.predict(X_test[features_v2])\n",
    "r2_pca = r2_score(y_test, y_pred_pca)\n",
    "mae_pca = mean_absolute_error(y_test, y_pred_pca)\n",
    "\n",
    "print(f\"PCA Model R¬≤: {r2_pca:.4f}\")\n",
    "print(f\"PCA Model MAE: {mae_pca:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24be6cd6",
   "metadata": {},
   "source": [
    "## 6. Subset Experiments (Movies WITH TMDb Data Only)\n",
    "\n",
    "**Why this matters:** The full dataset experiments above are diluted because 85% of movies have no plot data (PCA features = 0).\n",
    "\n",
    "These experiments filter to only the ~44k movies that have TMDb data, showing the **true impact** of plot features when a user actually provides a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f71c299f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T14:55:30.636748Z",
     "iopub.status.busy": "2026-01-28T14:55:30.636370Z",
     "iopub.status.idle": "2026-01-28T14:55:35.516128Z",
     "shell.execute_reply": "2026-01-28T14:55:35.515854Z",
     "shell.execute_reply.started": "2026-01-28T14:55:30.636723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset size: 37,905 movies\n",
      "Subset Train size: 26,533\n",
      "Subset Test size: 11,372\n",
      "\n",
      "--- Experiment 3: Baseline on Subset ---\n",
      "Subset Baseline R¬≤: 0.4757\n",
      "Subset Baseline MAE: 0.5766\n",
      "\n",
      "--- Experiment 4: Baseline + PCA on Subset ---\n",
      "Subset + PCA R¬≤: 0.4818\n",
      "Subset + PCA MAE: 0.5729\n",
      "\n",
      ">>> Plot feature improvement on subset: 0.0061 R¬≤ <<<\n"
     ]
    }
   ],
   "source": [
    "# Filter to movies WITH TMDb data\n",
    "df_subset = merged[merged['has_tmdb'] == 1].copy()\n",
    "print(f\"Subset size: {len(df_subset):,} movies\")\n",
    "\n",
    "# Train/test split on subset\n",
    "X_sub = df_subset.drop(columns=[target, 'tconst', 'imdbId', 'director_names', 'has_tmdb'])\n",
    "y_sub = df_subset[target]\n",
    "\n",
    "X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(\n",
    "    X_sub, y_sub, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Subset Train size: {len(X_train_sub):,}\")\n",
    "print(f\"Subset Test size: {len(X_test_sub):,}\")\n",
    "\n",
    "# Experiment 3: Baseline on Subset\n",
    "print(\"\\n--- Experiment 3: Baseline on Subset ---\")\n",
    "rf_sub_base = RandomForestRegressor(n_estimators=50, max_depth=10, n_jobs=-1, random_state=42)\n",
    "rf_sub_base.fit(X_train_sub[base_features], y_train_sub)\n",
    "\n",
    "y_pred_sub_base = rf_sub_base.predict(X_test_sub[base_features])\n",
    "r2_sub_base = r2_score(y_test_sub, y_pred_sub_base)\n",
    "mae_sub_base = mean_absolute_error(y_test_sub, y_pred_sub_base)\n",
    "\n",
    "print(f\"Subset Baseline R¬≤: {r2_sub_base:.4f}\")\n",
    "print(f\"Subset Baseline MAE: {mae_sub_base:.4f}\")\n",
    "\n",
    "# Experiment 4: Baseline + PCA on Subset\n",
    "print(\"\\n--- Experiment 4: Baseline + PCA on Subset ---\")\n",
    "features_sub_pca = base_features + pca_features\n",
    "rf_sub_pca = RandomForestRegressor(n_estimators=50, max_depth=10, n_jobs=-1, random_state=42)\n",
    "rf_sub_pca.fit(X_train_sub[features_sub_pca], y_train_sub)\n",
    "\n",
    "y_pred_sub_pca = rf_sub_pca.predict(X_test_sub[features_sub_pca])\n",
    "r2_sub_pca = r2_score(y_test_sub, y_pred_sub_pca)\n",
    "mae_sub_pca = mean_absolute_error(y_test_sub, y_pred_sub_pca)\n",
    "\n",
    "print(f\"Subset + PCA R¬≤: {r2_sub_pca:.4f}\")\n",
    "print(f\"Subset + PCA MAE: {mae_sub_pca:.4f}\")\n",
    "\n",
    "print(f\"\\n>>> Plot feature improvement on subset: {r2_sub_pca - r2_sub_base:.4f} R¬≤ <<<\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382bb5f3",
   "metadata": {},
   "source": [
    "## 7. Summary of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6e6a19c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T14:55:52.797100Z",
     "iopub.status.busy": "2026-01-28T14:55:52.796736Z",
     "iopub.status.idle": "2026-01-28T14:55:52.812236Z",
     "shell.execute_reply": "2026-01-28T14:55:52.811914Z",
     "shell.execute_reply.started": "2026-01-28T14:55:52.797075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RESULTS SUMMARY\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Features</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>vs_Baseline</th>\n",
       "      <th>vs_Subset_Baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Full Dataset - Baseline</td>\n",
       "      <td>298k</td>\n",
       "      <td>IMDb only</td>\n",
       "      <td>0.311746</td>\n",
       "      <td>0.853518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Full Dataset - Baseline + PCA</td>\n",
       "      <td>298k</td>\n",
       "      <td>IMDb + PCA (0-filled)</td>\n",
       "      <td>0.311876</td>\n",
       "      <td>0.853489</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. TMDb Subset - Baseline</td>\n",
       "      <td>44k</td>\n",
       "      <td>IMDb only</td>\n",
       "      <td>0.475729</td>\n",
       "      <td>0.576596</td>\n",
       "      <td>0.163983</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. TMDb Subset - Baseline + PCA</td>\n",
       "      <td>44k</td>\n",
       "      <td>IMDb + PCA (real)</td>\n",
       "      <td>0.481849</td>\n",
       "      <td>0.572896</td>\n",
       "      <td>0.170103</td>\n",
       "      <td>0.00612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Experiment Dataset               Features        R2  \\\n",
       "0        1. Full Dataset - Baseline    298k              IMDb only  0.311746   \n",
       "1  2. Full Dataset - Baseline + PCA    298k  IMDb + PCA (0-filled)  0.311876   \n",
       "2         3. TMDb Subset - Baseline     44k              IMDb only  0.475729   \n",
       "3   4. TMDb Subset - Baseline + PCA     44k      IMDb + PCA (real)  0.481849   \n",
       "\n",
       "        MAE  vs_Baseline  vs_Subset_Baseline  \n",
       "0  0.853518     0.000000                 NaN  \n",
       "1  0.853489     0.000130                 NaN  \n",
       "2  0.576596     0.163983             0.00000  \n",
       "3  0.572896     0.170103             0.00612  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "KEY INSIGHT:\n",
      "================================================================================\n",
      "On FULL dataset (85% without plots): PCA adds only +0.0001 R¬≤\n",
      "On SUBSET (movies WITH plots):       PCA adds +0.0061 R¬≤\n",
      "\n",
      "‚Üí When a user provides a plot, prediction accuracy improves significantly!\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Experiment': [\n",
    "        '1. Full Dataset - Baseline',\n",
    "        '2. Full Dataset - Baseline + PCA',\n",
    "        '3. TMDb Subset - Baseline',\n",
    "        '4. TMDb Subset - Baseline + PCA'\n",
    "    ],\n",
    "    'Dataset': ['298k', '298k', '44k', '44k'],\n",
    "    'Features': ['IMDb only', 'IMDb + PCA (0-filled)', 'IMDb only', 'IMDb + PCA (real)'],\n",
    "    'R2': [r2_base, r2_pca, r2_sub_base, r2_sub_pca],\n",
    "    'MAE': [mae_base, mae_pca, mae_sub_base, mae_sub_pca]\n",
    "})\n",
    "\n",
    "# Calculate improvements\n",
    "results['vs_Baseline'] = results['R2'] - r2_base\n",
    "results['vs_Subset_Baseline'] = [None, None, 0, r2_sub_pca - r2_sub_base]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "display(results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"KEY INSIGHT:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"On FULL dataset (85% without plots): PCA adds only +{r2_pca - r2_base:.4f} R¬≤\")\n",
    "print(f\"On SUBSET (movies WITH plots):       PCA adds +{r2_sub_pca - r2_sub_base:.4f} R¬≤\")\n",
    "print(\"\\n‚Üí When a user provides a plot, prediction accuracy improves significantly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2i69mu59qxj",
   "source": "## 9. Future Ideas\n\n**Director Rating Feature:**\n- Find a database with director quality/reputation scores\n- If a user provides a director name, check if they're in our dataset\n- If found, use their historical average rating to modify the prediction\n- Hypothesis: Known directors have predictable quality patterns (e.g., Spielberg ‚Üí higher expected rating)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "i4mbwl2ppic",
   "source": "## 8. API Design Decision: numVotes as Optional\n\n**Problem:** The current API requires `numVotes` as input, but this is **data leakage** for new movies.\n\nIf the use case is *\"Predict the rating of a movie BEFORE it's released\"*, then `numVotes` won't exist yet. The user can't provide a value they don't have.\n\n**Solution:** Make `numVotes` optional with **median imputation**.\n- If user provides numVotes ‚Üí use it (e.g., predicting for an existing movie)\n- If user doesn't provide numVotes ‚Üí use the median from training data\n\n**Why median instead of mean?**\n- `numVotes` is heavily right-skewed (few blockbusters with millions of votes)\n- Median is more robust to outliers than mean",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "enmn540k2r",
   "source": "# Calculate numVotes statistics to justify median imputation\nprint(\"numVotes Distribution Analysis\")\nprint(\"=\" * 50)\n\nnum_votes = merged['numVotes']\nprint(f\"Mean:   {num_votes.mean():,.0f}\")\nprint(f\"Median: {num_votes.median():,.0f}  ‚Üê USE THIS FOR IMPUTATION\")\nprint(f\"Min:    {num_votes.min():,}\")\nprint(f\"Max:    {num_votes.max():,}\")\nprint(f\"Std:    {num_votes.std():,.0f}\")\n\nprint(f\"\\nPercentiles:\")\nfor p in [25, 50, 75, 90, 95, 99]:\n    print(f\"  {p}th: {num_votes.quantile(p/100):,.0f}\")\n\nprint(f\"\\n‚Üí MEDIAN_NUM_VOTES = {int(num_votes.median())}\")\nprint(\"  This value will be used in preprocessing.py when numVotes is not provided.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da8c24-a151-48ce-8888-52826d280dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}